import csv
import spacy
import pandas as pd
from collections import Counter

#Загрузка модели spaCy
nlp = spacy.load("en_core_web_sm")
import pandas as pd

df = pd.read_csv('/content/your_csv.csv') #разработанный csv на базе Oxford и j-cefr лежит в отдельном файле:) 
print(df.columns)
#Чтение
with open('/content/your_csv.csv', 'r', encoding='utf-8') as file:
    content = file.read()

#Заменяем возможные проблемы с разделителями
content = content.replace(';', ',')

#Сохраняем исправленный файл
with open('/content/your_csv.csv', 'w', encoding='utf-8') as file:
    file.write(content)

#загрузка нашей базки
#Градация CEFR
cefr_order = {'A1': 1, 'A2': 2, 'B1': 3, 'B2': 4, 'C1': 5, 'C2': 6}

#Загрузка слов и уровней с приоритетом на минимальный уровень
word_levels = {}
level = row['CEFR Level'].strip().upper()
with open('/content/hahahacknuli_oxford_cefr_words1.csv', encoding='utf-8') as csvfile:
    reader = csv.DictReader(csvfile, delimiter=',')
    for row in reader:
        word = row['Word'].strip().lower()
        level = row['CEFR Level'].strip().upper()
        #костыль!! насильно меняем c1 на b1 из-за неточности статистики. при желании можно закомментить - поставить # перед командой. она не будет выполняться.
        if level == 'C1':
            level = 'B1'

        #Проверка: если слово уже есть, сохраняем более простой уровень (сделано для разночтений файла)
        if word in word_levels:
            existing_level = word_levels[word]
            if cefr_order[level] < cefr_order.get(existing_level, 7):
                word_levels[word] = level
        else:
            word_levels[word] = level


#Чтение текста учебника
with open('/content/spotlight3.txt', 'r', encoding='utf-8') as file:
    text = file.read().lower()

#Обработка текста
doc = nlp(text)
lemmas = []
pos_tags = []
for token in doc:
    if not token.is_stop and not token.is_punct:
        lemmas.append(token.lemma_)
        pos_tags.append((token.lemma_, token.pos_))

#Подсчёт частоты лемм
lemma_freq = Counter(lemmas)

#Уникальные леммы
unique_lemmas = set(lemmas)

#Формирование таблицы: слово - уровень - частота - POS
pos_dict = dict(pos_tags)
word_level_table = []
for word in unique_lemmas:
    level = word_levels.get(word, 'unknown')
    freq = lemma_freq[word]
    pos = pos_dict.get(word, 'X')  # Если не найден POS — X
    word_level_table.append({'word': word, 'level': level, 'frequency': freq, 'pos': pos})

#Создание DataFrame
df = pd.DataFrame(word_level_table)

#Удаление unknown
df = df[df['level'] != 'unknown']

#Удаление дублей
df = df.drop_duplicates(subset='word')

#Сортировка
df = df.sort_values(by=['level', 'frequency'], ascending=[True, False])

#Сохраняем основную таблицу
df.to_csv('/content/3word_levels_table.csv', index=False, encoding='utf-8')

#Топ-10 по частоте на уровень. Число можно поменять.
top_by_level = df.groupby('level').apply(lambda x: x.nlargest(10, 'frequency')).reset_index(drop=True)
top_by_level.to_csv('/content/3top10_by_level.csv', index=False, encoding='utf-8')

#Распределение частей речи
pos_counts = df['pos'].value_counts().reset_index()
pos_counts.columns = ['pos', 'count']
pos_counts.to_csv('/content/3pos_distribution.csv', index=False, encoding='utf-8')


#Вывод 5 примеров слов для каждого уровня
#Примеры самых частотных слов для каждого уровня (по 5)
print("\nПримеры самых частотных слов для каждого уровня:")
top_examples = df.groupby('level').apply(lambda x: x.nlargest(5, 'frequency')).reset_index(drop=True)
for level in sorted(top_examples['level'].unique()):
    words = top_examples[top_examples['level'] == level]['word'].tolist()
    print(f"{level}: {', '.join(words)}")


#Визуализация

import matplotlib.pyplot as plt
import seaborn as sns

#Стиль. Также можно заменть. Подробнее: документация seaborn
sns.set(style="whitegrid")

#Гистограмма: количество слов на каждом уровне
plt.figure(figsize=(10, 5))
sns.countplot(data=df, x='level', order=sorted(df['level'].unique()))
plt.title('Количество слов по уровням CEFR')
plt.xlabel('Уровень CEFR')
plt.ylabel('Количество слов')
plt.tight_layout()
plt.savefig('/content/plot_cefr_levels.png')
plt.show()

#Гистограмма: частота слов топ-10 по каждому уровню
plt.figure(figsize=(20, 10))
sns.barplot(data=top_by_level, x='level', y='frequency', hue='word')
plt.title('Топ-10 слов по частоте на каждом уровне')
plt.xlabel('Уровень CEFR')
plt.ylabel('Частота')
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', title='Слово')
plt.tight_layout()
plt.savefig('/content/plot_top10_words.png')
plt.show()

#Гистограмма: распределение частей речи
plt.figure(figsize=(10, 5))
sns.barplot(data=pos_counts, x='pos', y='count')
plt.title('Распределение по частям речи')
plt.xlabel('Часть речи')
plt.ylabel('Количество слов')
plt.tight_layout()
plt.savefig('/content/plot_pos_distribution.png')
plt.show()
